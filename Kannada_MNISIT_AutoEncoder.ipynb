{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Kannada MNIST AutoEncoder\n",
        "## Introduction\n",
        "This project aims to build a simple autoencoder using Keras tensorflow. It will be a simple model that can be used to understand the workings of a neural network.<br>\n",
        "As Wikipedia defines it, [Autoencoder](https://en.wikipedia.org/wiki/Autoencoder) usually \"learns representation(encoding) for a set of data, typically for dimensionality reduction, by training the network to igonore insignificant data(noise).\" That's a pretty interesting definition. So, in this network, we'll work through some of the nuances associated with the concept.\n",
        "\n",
        " The dataset was taken from kaggle. \n",
        "The link is given below. <br>\n",
        "[Kannada MNIST dataset](https://www.kaggle.com/datasets/higgstachyon/kannada-mnist/code)"
      ],
      "metadata": {
        "id": "Uc0oesyYpNuN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jLnvZ-oso1yH"
      },
      "outputs": [],
      "source": [
        "## Importing the basic required libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# The deep learning libraries that are going to be used\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#assigning a variable for the os directory\n",
        "dir = './Kannada_MNIST'\n",
        "\n",
        "#assigning all testing and training values\n",
        "x_train = np.load( os.path.join(dir,'X_kannada_MNIST_train.npz'))['arr_0']\n",
        "x_test  = np.load( os.path.join(dir,'X_kannada_MNIST_test.npz'))['arr_0']\n",
        "y_train = np.load( os.path.join(dir,'y_kannada_MNIST_train.npz'))['arr_0']\n",
        "y_test  = np.load( os.path.join(dir,'y_kannada_MNIST_test.npz'))['arr_0']\n",
        "\n",
        "#printing shapes of the basic arrays\n",
        "print(x_train.shape, x_test.shape)"
      ],
      "metadata": {
        "id": "i4yGl3qyLf2r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#just plotting some images\n",
        "# Creates different random images from the dataset each time\n",
        "\n",
        "# A plotting function\n",
        "def plot_stuff(X,y, n=5):\n",
        "  array = np.random.randint(1,60000,n)\n",
        "  plt.figure(figsize=(20,4))\n",
        "  #\n",
        "  for i in range(n):\n",
        "    ax = plt.subplot(2,n,i+1)\n",
        "    plt.imshow(X[array[i]])\n",
        "    plt.title(y[array[i]])\n",
        "\n",
        "plot_stuff(x_train,y_train)"
      ],
      "metadata": {
        "id": "Ld6jq_SyXdEe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalization of input for proper working with MLP models\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "\n",
        "X_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
        "X_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))"
      ],
      "metadata": {
        "id": "WZHg8O9_VeDd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing all other libaries required to do this\n",
        "from keras.layers import Input, Dense, Flatten\n",
        "from keras.models import Model\n",
        "from keras import regularizers"
      ],
      "metadata": {
        "id": "sTp7mXOrOFlT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Defining an Autoencoder using Deep multi Layer perceptrons\n",
        "Enc_dimensions = 32\n",
        "input_img = Input(shape=(784,))\n",
        "\n",
        "#defining the encoder architecture\n",
        "encoded = Dense(128,activation = 'relu')(input_img)\n",
        "encoded = Dense(64, activation = 'relu')(encoded)\n",
        "encoded = Dense(32, activation = 'sigmoid')(encoded)\n",
        "\n",
        "#defining the decoder architecture\n",
        "decoded = Dense(32, activation = 'sigmoid')(encoded)\n",
        "decoded = Dense(64,activation = 'relu')(decoded)\n",
        "decoded = Dense(128,activation = 'relu')(decoded)\n",
        "decoded = Dense(784,activation = 'relu')(decoded)\n",
        "# Building a model in a single shot, where the layers are properly stacked\n",
        "AutoEnc_model = Model(input_img, decoded)"
      ],
      "metadata": {
        "id": "OrLeQBknM9j6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AutoEnc_model.summary()"
      ],
      "metadata": {
        "id": "QIOgv9R2dohF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Alternative Way to build by serperate Encoder and Decoding stacks.\n",
        "# Legacy Code\n",
        "\n",
        "# Encoder module seperately\n",
        "AutoEncKan_Encoder = Model(input_img, encoded)\n",
        "\n",
        "# Decoder Model Seperately\n",
        "Enc_input = Input(shape =( Enc_dimensions,))\n",
        "Dec_layers = AutoEncKan_Encoder[-1]\n",
        "\n",
        "#Combining both parts to create a single architecture\n",
        "AutoEncKan_Decoder = Model(Enc_input, Dec_layers(Enc_input))"
      ],
      "metadata": {
        "id": "QPnWgceRUPNd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AutoEnc_model.compile(optimizer = 'adadelta',loss='binary_crossentropy')"
      ],
      "metadata": {
        "id": "MemKPm_YQU3U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Test = AutoEnc_model.fit(X_train,X_train,\n",
        "                         epochs = 100,\n",
        "                         batch_size = 256,\n",
        "                         shuffle = True,   \n",
        "                         validation_data=(X_test,X_test)\n",
        "                         )"
      ],
      "metadata": {
        "id": "yqNXAtniQw1X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Predict = AutoEnc_model.predict(x_test)"
      ],
      "metadata": {
        "id": "q-JFmUFeRo2y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## References\n",
        "https://keras.io/ <br>\n",
        "https://machinelearningmastery.com/autoencoder-for-classification/  <br>\n",
        "https://www.kaggle.com/code/shubhams9k96/denoising-using-autoencoders/notebook "
      ],
      "metadata": {
        "id": "yfp3f28zS2Fz"
      }
    }
  ]
}
